{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning\n",
    "============\n",
    "\n",
    "- The learning rate, $\\alpha$, is most important hyperparameter for the most applications.\n",
    "- The momentum term $\\beta$, the number of hidden units, and the mini-batch size are considered the second important hyperparameters.\n",
    "\n",
    "#### How to select the hyperparameters?\n",
    "- In deep learning, as the number of the hyperparameters tends to be large comparing to traditional machine learning algms choose the hyperparameter in random; don't use grid to choose them.\n",
    "- Another reason to choose the hyperparameter in random is that you don't know which hyperparameters are important than others for your application.\n",
    "- A good practice when you sampling a hyperparameter is to follow Coarse to fine sampling scheme (or search process)\n",
    "\n",
    "<span class=\"text-danger\">PLEASE revisit video 2 of the Week</span>\n",
    "- sampling hyperparamters at random does not mean sampling uniformaly at random.\n",
    "- For example if you want to sample the hyperparameter $\\beta$ of the exponenetially weighted moving average, then you need to know that as the value of $\\beta$ approaching 1 the behaviour of the algorithms at hands dramatically changes since a small change exponentially makes the algorithm average over thousands of last samples. \n",
    "\n",
    "- In terms of your settings for the hyperparameters, though, I've seen that intuitions do get stale. So even if you work on just one problem, say logistics, you might have found a good setting for the hyperparameters and kept on developing your algorithm, or maybe seen your data gradually change over the course of several months, or maybe just upgraded servers in your data center. And because of those changes, the best setting of your hyperparameters can get stale. So I recommend maybe just retesting or reevaluating your hyperparameters at least once every several months to make sure that you're still happy with the values you have. \n",
    "\n",
    "- in terms of how people go about searching for hyperparameters, I see maybe two major schools of thought, or maybe two major different ways in which people go about it. One way is if you babysit one model (Pandas). \n",
    "- the way to choose between these two approaches -Panada and Caviar- is really a function of how much computational resources you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
