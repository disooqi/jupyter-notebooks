{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nجملة مفيدة\\nشبه جملة\\nجملة أسمية\\nجملة فعلية\\nظرف\\nأسم\\nفعل\\nحرف\\nتاء الفاعل \\nتاء التأنيث\\nياء المخاطبة\\nنون التوكيد\\nحرف النداء\\nحرف جر\\nالاضافة\\nضمير\\nجار\\nمجرور\\nالاسم النكرة\\nالاسم المعرفة\\nالتنوين\\nالاسم المفرد \\nالاسم المثنى\\nالجمع\\nجمع المذكر السالم\\nجمع المؤنث السالم\\nجمع التكسير\\nالمصدر\\nمصدر صريح \\nمصدر مؤول\\nالعَلم\\nإسم الاشارة\\nالاسم الموصول \\nالمعرف بأل\\nأسماء الشرط\\nأسماء الاستفهام\\nأسماء الافعال\\nالاعداد المركبة\\nالمضاف الى المعرف بأل\\nالفعل الماضي\\nالفعل الحاضر\\nفعل الامر\\nحروف العلة\\nاسم معرب\\nاسم مبني\\n\\n'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "جملة مفيدة\n",
    "شبه جملة\n",
    "جملة أسمية\n",
    "جملة فعلية\n",
    "ظرف\n",
    "أسم\n",
    "فعل\n",
    "حرف\n",
    "تاء الفاعل \n",
    "تاء التأنيث\n",
    "ياء المخاطبة\n",
    "نون التوكيد\n",
    "حرف النداء\n",
    "حرف جر\n",
    "الاضافة\n",
    "ضمير\n",
    "جار\n",
    "مجرور\n",
    "الاسم النكرة\n",
    "الاسم المعرفة\n",
    "التنوين\n",
    "الاسم المفرد \n",
    "الاسم المثنى\n",
    "الجمع\n",
    "جمع المذكر السالم\n",
    "جمع المؤنث السالم\n",
    "جمع التكسير\n",
    "المصدر\n",
    "مصدر صريح \n",
    "مصدر مؤول\n",
    "العَلم\n",
    "إسم الاشارة\n",
    "الاسم الموصول \n",
    "المعرف بأل\n",
    "أسماء الشرط\n",
    "أسماء الاستفهام\n",
    "أسماء الافعال\n",
    "الاعداد المركبة\n",
    "المضاف الى المعرف بأل\n",
    "الفعل الماضي\n",
    "الفعل الحاضر\n",
    "فعل الامر\n",
    "حروف العلة\n",
    "اسم معرب\n",
    "اسم مبني\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(1, 3), match='\\\\g'>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "whiteSpace_char_pattern = re.compile(r'\\s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FATHATAN         = u'\\u064b'\n",
    "DAMMATAN         = u'\\u064c'\n",
    "KASRATAN         = u'\\u064d'\n",
    "AHROF_ELGAR      = ('على', 'الى', 'من', 'في')\n",
    "AHROF            = ('أن', 'هل', 'لم')\n",
    "pronouns          = ('أنا', 'أنت', 'هو', 'هي', 'هما', 'هن', 'أنتما', 'أنتن') \n",
    "#, '', '', '', '', '', '', '', '', '', '')\n",
    "\n",
    "\n",
    "def is_pronoun(token):\n",
    "    if not whiteSpace_char_pattern.search(token):\n",
    "        if token in pronouns:\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_pronoun():\n",
    "    pass\n",
    "\n",
    "def is_proper_noun():\n",
    "    pass\n",
    "\n",
    "def is_ESM_ESHARA():\n",
    "    pass\n",
    "\n",
    "def is_ESM_MAWSOOL():\n",
    "    pass\n",
    "\n",
    "def is_defined_with_AL():\n",
    "    pass\n",
    "\n",
    "def is_added_to_the_defined_with_AL():\n",
    "    pass\n",
    "\n",
    "def is_called_intended_to_mention():\n",
    "    pass\n",
    "\n",
    "def is_ESM_MABNY(token):\n",
    "    if token in pronouns + ASMAA_ALESHARA + ASMAA_MAWSOLA + ASMAA_SHART + ASMAA_ESTEFHAM + BA3D_ELZOROF + \\\n",
    "    ASMAA_ELAF3AL + ALAA3DAD_ALMORAKABA:\n",
    "        return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-111-0822363f22d1>, line 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-111-0822363f22d1>\"\u001b[1;36m, line \u001b[1;32m33\u001b[0m\n\u001b[1;33m    return self.token_POS == 'F' and         self.defined == None and\u001b[0m\n\u001b[1;37m                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "original_POS = ('E', 'F', 'H')\n",
    "\n",
    "class Token:    \n",
    "    \n",
    "    def __init__(self, txt):\n",
    "        self.text = txt\n",
    "        self.token_POS = None # values 'E', 'F', 'H'\n",
    "        self.defined = None # values True or False\n",
    "        self.number = None\n",
    "        self.verb_tense = None\n",
    "        self.mo3rab = None\n",
    "        \n",
    "        \n",
    "#     def setPOS(self, pos_id):\n",
    "#         self.token_POS = original_POS[pos_id]\n",
    "        \n",
    "    def is_defined(self):\n",
    "        # الاسم النكرة هو ما دل على غير معين \n",
    "        # الاسم المعرفة هو ما دل على معين بذاته\n",
    "        if is_pronoun() or \\\n",
    "        is_proper_noun() or \\\n",
    "        is_ESM_ESHARA() or \\\n",
    "        is_ESM_MAWSOOL() or \\\n",
    "        is_defined_with_AL() or \\\n",
    "        is_added_to_the_defined_with_AL() or \\\n",
    "        is_called_intended_to_mention():\n",
    "            return True\n",
    "        \n",
    "    def validate(self):\n",
    "        if self.token_POS:\n",
    "            return validate_noun() or validate_verb() or validate_particle()\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "    def validate_noun(self):\n",
    "        return self.token_POS == 'E' and \\\n",
    "        verb_tense == None\n",
    "    \n",
    "    def validate_verb(self):\n",
    "        return self.token_POS == 'F' and \\\n",
    "        self.defined == None and\n",
    "        self.mo3rab == None\n",
    "        \n",
    "    def validate_particle(self):\n",
    "        return self.token_POS == 'H' and \\\n",
    "        self.defined == None and \\\n",
    "        self.number == None and \\\n",
    "        verb_tense == None and\n",
    "        self.mo3rab == None\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "####################################################################################\n",
    "class Sentence:\n",
    "    def __init__(self, txt):\n",
    "        self.raw_sentence = txt.strip()\n",
    "        self.tokens_list = self.raw_sentence.split()\n",
    "        self.tokens = [Token(token) for token in self.tokens_list]\n",
    "        self.set_token_POS_auto()\n",
    "        self.useful_sentence = False # False does NOT means semi-sentence\n",
    "        self.semi_sentence = False\n",
    "        \n",
    "    def is_useful(self): # جملة مفيدة\n",
    "        # الجملة المفيدة ما تركب من كلمتين أو أكثر وأفاد معنى تاما\n",
    "        return self.useful_sentence\n",
    "    \n",
    "    def is_semi_sentence(self):\n",
    "        # ظرف بعد مضاف إليه\n",
    "        # جار ومجرور\n",
    "        pass\n",
    "    \n",
    "    def is_nominal_sentence(self):\n",
    "        # هي التي تبدأبأسم أو بضمير\n",
    "        if self.useful_sentence and (self.tokens[0].token_POS == 'E' or is_pronoun(tokens[0].text)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def is_verbal_sentence(self):\n",
    "        # هي التي تبدأ بفعل مثل \n",
    "        if self.useful_sentence and self.tokens[0].token_POS == 'F':\n",
    "            return True \n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def set_token_POS_auto(self): #page 17 of the book \n",
    "        for i, token in enumerate(self.tokens):\n",
    "            if token.text.startswith('ال') or \\\n",
    "            token.text.endswith((FATHATAN, DAMMATAN, KASRATAN)) or \\\n",
    "            self.tokens[i-1] == 'يا' or \\\n",
    "            self.tokens[i-1] in AHROF_ELGAR:\n",
    "            # يمكن جره بالاضافة\n",
    "            # يمكن الاسناد اليه اي الاخبار عنه\n",
    "                token.token_POS = 'E'\n",
    "            elif False:\n",
    "            # متصل بتاء الفاعل\n",
    "            # متصل بتاء التأنيث\n",
    "            # متصل بياء المخاطبة\n",
    "            # متصل بنون التوكيد\n",
    "                token.token_POS = 'F'\n",
    "            elif token.text in AHROF_ELGAR+AHROF:\n",
    "                # هو كل كلمة ليس لها معنى الا مع غيرها\n",
    "                token.token_POS = 'H'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "العلم نور\n",
      "E\n"
     ]
    }
   ],
   "source": [
    "s1 = Sentence(\"العلم نور\")\n",
    "print(s1.raw_sentence)\n",
    "print(s1.tokens[0].token_POS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
