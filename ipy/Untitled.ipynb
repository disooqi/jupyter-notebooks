{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import os\n",
    "from collections import deque\n",
    "import re\n",
    "import random\n",
    "from itertools import zip_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = '/home/disooqi/RBGParser/data'\n",
    "\n",
    "train_path = os.path.join(data_dir, 'spmrl.train.conll')\n",
    "test_path = os.path.join(data_dir, 'spmrl.test.conll')\n",
    "\n",
    "tokfile = os.path.join(data_dir, 'spmrl_train_conll.tok')\n",
    "\n",
    "farasa_output = os.path.join(data_dir, 'for_aligning')\n",
    "RBGParser_train = os.path.join(data_dir, 'arabic.train.farasa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ar = \"\\u0627\\u0625\\u0622\\u0623\\u0621\\u0628\\u062a\\u062b\\u062c\\u062d\\u062e\\u062f\\u0630\\u0631\\u0632\\u0633\\u0634\\u0635\\u0636\\u0637\\u0638\\u0639\\u063a\\u0641\\u0642\\u0643\\u0644\\u0645\\u0646\\u0647\\u0648\\u064a\\u0649\\u0629\\u0624\\u0626\\u064e\\u064b\\u064f\\u064c\\u0650\\u064d\\u0652\\u0651\"\n",
    "buck = \"A<|>'btvjHxd*rzs$SDTZEgfqklmnhwyYp&}aFuNiKo~\"\n",
    "b2a_translation_table = str.maketrans(buck, ar)\n",
    "a2b_translation_table = str.maketrans(ar, buck)\n",
    "\n",
    "def utf82buck(kdinput):\n",
    "    return kdinput.translate(a2b_translation_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = re.compile(r'\\.\\.+')\n",
    "p2 = re.compile(r';')\n",
    "p3 = re.compile(r'/')\n",
    "p4 = re.compile(r'_')\n",
    "fp= re.compile(r'\\d+\\.\\d+')\n",
    "fp2= re.compile(r'\\d+\\.\\d+\\.\\d+')\n",
    "fp3= re.compile(r'\\.\\d+')\n",
    "ap= re.compile(r'\\d+,\\d+')\n",
    "with codecs.open(train_path, encoding='utf-8') as tf:\n",
    "    with codecs.open(tokfile, encoding='utf-8', mode='w') as tt:\n",
    "        for line in tf:\n",
    "            fields = line.strip().split()\n",
    "            \n",
    "            if len(fields) == 10:\n",
    "                sentence = line.strip().split()[1]\n",
    "                sentence = p.sub('.',sentence)\n",
    "                sentence = p2.sub(',',sentence)\n",
    "                sentence = p3.sub(',',sentence)\n",
    "                sentence = p4.sub(',',sentence)\n",
    "                sentence = ap.sub(str(random.randrange(1,1000)), sentence)\n",
    "                sentence = fp2.sub(str(random.randrange(1,1000)), sentence)\n",
    "                sentence = fp.sub(str(random.randrange(1,1000)), sentence)\n",
    "                sentence = fp3.sub(str(random.randrange(1,1000)), sentence)\n",
    "                \n",
    "                tt.write(sentence)\n",
    "            else:\n",
    "                tt.write(line.strip())\n",
    "            tt.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col2 = list()\n",
    "col7 = list()\n",
    "col8 = list()\n",
    "col9 = list()\n",
    "col10 = list()\n",
    "\n",
    "with codecs.open(train_path, encoding='utf-8') as tf:\n",
    "    for line in tf:\n",
    "            fields = line.strip().split()\n",
    "            if len(fields) == 10:\n",
    "                col2.append(fields[1])\n",
    "                col7.append(fields[6])\n",
    "                col8.append(fields[7])\n",
    "                col9.append(fields[8])\n",
    "                col10.append(fields[9])\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OBJ', 'PRD', 'TMZ', 'IDF', '---', 'SBJ', 'MOD', 'TPC']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(451280, 451280, 451280, 451280, 451280)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(list(Counter(col8)))\n",
    "len(col2), len(col7),len(col8),len(col9),len(col10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col2_q = deque(col2[:])\n",
    "col7_q = deque(col7[:])\n",
    "col8_q = deque(col8[:])\n",
    "col9_q = deque(col9[:])\n",
    "col10_q = deque(col10[:])\n",
    "\n",
    "with codecs.open(farasa_output, encoding='utf-8') as tf:\n",
    "    with codecs.open(RBGParser_train, encoding='utf-8', mode='w') as tt:\n",
    "        count = 0 \n",
    "        for org_line in tf:\n",
    "            org_tokens = org_line.strip().split()\n",
    "            \n",
    "            farasa_line = tf.readline()\n",
    "            farasa_tokens = farasa_line.strip().split()[1:-1]\n",
    "            #print(len(org_tokens), len(farasa_tokens), farasa_tokens[0], farasa_tokens[-1])\n",
    "            #farasa_q = deque(farasa_tokens)\n",
    "            # sentence = list()\n",
    "            if not len(org_tokens) == len(farasa_tokens):\n",
    "                count += 1\n",
    "                print (\"the 2 sentences are not equal\", count)\n",
    "                print (org_line)\n",
    "                print(len(org_tokens), len(farasa_tokens), farasa_tokens[0], farasa_tokens[-1])\n",
    "                #print(org_line)\n",
    "                #print(farasa_line)\n",
    "                print([print(tup) for tup in list(zip_longest(org_tokens, farasa_tokens))])\n",
    "                print()\n",
    "                \n",
    "            for ID, token in enumerate(zip(org_tokens, farasa_tokens)):\n",
    "                #print('\\n')\n",
    "                #print(token[0], token[1])\n",
    "                #print('='*40)\n",
    "                \n",
    "                fields = list()\n",
    "                feats = {'det':'n', 'gen':'na', 'num':'na'}\n",
    "                fields.append(str(ID+1))\n",
    "                fields.append(col2_q.popleft())\n",
    "                # fields.append(token[0])\n",
    "                # first = farasa_q.popleft().split('/')\n",
    "                # print(token[0], token[1])\n",
    "                \n",
    "                tmp = token[1].split('|')\n",
    "                if len(tmp) > 1:\n",
    "                    pos = ''\n",
    "                    for t in tmp:\n",
    "                        tok_pos = t.split('/')\n",
    "                        if '+' not in tok_pos[0]:\n",
    "                            fields.append(utf82buck(tok_pos[0]))\n",
    "                            pos_gen_num = tok_pos[1].split('-')\n",
    "                            if len(pos_gen_num) == 2:\n",
    "                                fields.append(pos_gen_num[0])\n",
    "                                fields.append(pos_gen_num[0])\n",
    "                                \n",
    "                                feats['gen'] = pos_gen_num[1][:1]\n",
    "                                feats['num'] = pos_gen_num[1][1:]\n",
    "                            else:\n",
    "                                fields.append(pos_gen_num[0])\n",
    "                                fields.append(pos_gen_num[0])\n",
    "\n",
    "                        elif tok_pos[0] == 'ال+':\n",
    "                            feats['det'] = 'y'\n",
    "                        else:\n",
    "                            pos += '+'+tok_pos[1]\n",
    "                    else:\n",
    "                        if len(fields) != 5: # at this moment\n",
    "                            fields.append(fields[1])\n",
    "                            fields.append(pos[1:])\n",
    "                            fields.append(pos[1:])\n",
    "                            #print(len(fields), fields)\n",
    "                            \n",
    "                else:                    \n",
    "                    feats['det'] = 'n'\n",
    "                    tok_pos = tmp[0].split('/')\n",
    "                    if '+' in tok_pos[0]:\n",
    "                        tok_pos[0] = tok_pos[0].replace('+', '')\n",
    "                        \n",
    "                    fields.append(utf82buck(tok_pos[0]))\n",
    "                    pos_gen_num = tok_pos[1].split('-')\n",
    "                    if len(pos_gen_num) == 2:\n",
    "                        fields.append(pos_gen_num[0])\n",
    "                        fields.append(pos_gen_num[0])\n",
    "                        feats['gen'] = pos_gen_num[1][:1]\n",
    "                        feats['num'] = pos_gen_num[1][1:]\n",
    "                    else:\n",
    "                        fields.append(pos_gen_num[0])\n",
    "                        fields.append(pos_gen_num[0])\n",
    "\n",
    "                        \n",
    "                fields.append('det='+feats['det']+'|gen='+feats['gen']+'|num='+feats['num'])\n",
    "                fields.append(col7_q.popleft())\n",
    "                fields.append(col8_q.popleft())\n",
    "                fields.append(col9_q.popleft())\n",
    "                fields.append(col10_q.popleft())\n",
    "                \n",
    "                fis = '\\t'.join(fields)\n",
    "                offf = len(fis.strip().split())\n",
    "           \n",
    "                if offf != 10:\n",
    "                    print(fis)\n",
    "                \n",
    "                tt.write('\\t'.join(fields))\n",
    "                tt.write('\\n')\n",
    "            tt.write('\\n')\n",
    "            \n",
    "                # print('\\t'.join(fields))\n",
    "            #break\n",
    "            tf.readline()\n",
    "            tf.readline() # just consuming empty line\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = 'ال+/DETمتحد/ADJ-MP+ة/NSUFF'\n",
    "d.split('+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
