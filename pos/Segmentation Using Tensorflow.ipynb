{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.keras as keras\n",
    "from tensorflow.contrib.keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold_1 = {'train':\"./seg_data/egy/data_1.train.conll\", \n",
    "          'dev':\"./seg_data/egy/data_1.dev.conll\", \n",
    "          'test':\"./seg_data/egy/data_1.test.conll\"}\n",
    "\n",
    "fold_2 = {'train':\"./seg_data/egy/data_2.train.conll\", \n",
    "          'dev':\"./seg_data/egy/data_2.dev.conll\", \n",
    "          'test':\"./seg_data/egy/data_2.test.conll\"}\n",
    "\n",
    "folds = {'1':fold_1, '2':fold_2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for training\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tweets (instances): 257\n",
      "number of steps (cells): 156\n",
      "number of units in the input layer (# features) 127\n",
      "\n",
      "The shape of the X_batch should be: (m, 156, 127), where `m` is the number of instances\n"
     ]
    }
   ],
   "source": [
    "train_sentences = list()\n",
    "train_trgs = list()\n",
    "\n",
    "index2trg = ['S', 'B', 'E', 'M', 'WB', 'EOT']\n",
    "trg2index = {'S': 0, 'B': 1, 'E': 2, 'M': 3, 'WB':4, 'EOT':5}\n",
    "\n",
    "ch_set = set()\n",
    "index2ch = ['<PAD>', '<UNK>']\n",
    "ch2index = dict() #{'<PAD>': 0, '<UNK>': 1}\n",
    "\n",
    "with codecs.open(folds['1']['train'], encoding=\"utf-8\") as eg_tr1:\n",
    "    sentence = list()\n",
    "    sentence_trg = list()\n",
    "    for i, line in enumerate(eg_tr1):\n",
    "        \n",
    "        line_elements = line.strip().split()\n",
    "        if line_elements:\n",
    "            ch_set.add(line_elements[0])\n",
    "            sentence.append(line_elements[0])\n",
    "            sentence_trg.append(line_elements[1])\n",
    "        else:\n",
    "            ch_set.add(\"EOT\")\n",
    "            sentence.append(\"EOT\")\n",
    "            sentence_trg.append(\"EOT\")\n",
    "            # print(sentence)\n",
    "            train_sentences.append(sentence)\n",
    "            train_trgs.append(sentence_trg)\n",
    "        \n",
    "            # print(train_sentences[0])\n",
    "            sentence = list()\n",
    "            sentence_trg = list()\n",
    "            \n",
    "            #             del sentence[:]\n",
    "            #             del sentence_trg[:]\n",
    "    else:\n",
    "        chars = list(ch_set)\n",
    "        index2ch.extend(chars)\n",
    "        for i, ch in enumerate(index2ch):\n",
    "            ch2index[ch] = i\n",
    "\n",
    "n_instances = len(train_sentences)\n",
    "n_steps = max(map(lambda x: len(x), train_sentences))\n",
    "n_inputs = len(index2ch)\n",
    "\n",
    "print('number of tweets (instances):',n_instances)\n",
    "print('number of steps (cells):', n_steps)\n",
    "print('number of units in the input layer (# features)', n_inputs)\n",
    "print()\n",
    "print('The shape of the X_batch should be: (m, {}, {}), where `m` is the number of instances'.format(n_steps, n_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare inputs for the network\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 156)\n",
      "(257, 156, 127)\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "#####  1  #######\n",
    "#################\n",
    "train_char_index = list()\n",
    "\n",
    "for sentence in train_sentences:\n",
    "    char_index = list(map(lambda ch: ch2index[ch], sentence))\n",
    "    train_char_index.append(char_index)\n",
    "\n",
    "# the_length of_the_input_sequence_for_each_instance\n",
    "the_length_of_the_input_sequence_for_each_instance = list(map(lambda x: len(x), train_sentences))\n",
    "\n",
    "\n",
    "###################################################\n",
    "#####  2 Padding for short sentences  #############\n",
    "###################################################\n",
    "# https://stackoverflow.com/questions/38592324/one-hot-encoding-using-numpy\n",
    "# https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t\n",
    "X = keras.preprocessing.sequence.pad_sequences(train_char_index, maxlen=n_steps, padding='post')\n",
    "print(X.shape)\n",
    "\n",
    "###########################################################\n",
    "#####  3 replace  char index with hot vector  #############\n",
    "###########################################################\n",
    "# https://stackoverflow.com/questions/36960320/convert-a-2d-matrix-to-a-3d-one-hot-matrix-numpy\n",
    "# http://localhost:8888/notebooks/ml/Neural%20Network%20-%20Backpropagation.ipynb\n",
    "targets = np.array(X).reshape(-1)\n",
    "X_one_hot = np.eye(n_inputs)[targets]\n",
    "X_batch = X_one_hot.reshape(n_instances,n_steps,n_inputs)\n",
    "# X_batch = tf.one_hot(X, n_inputs)\n",
    "print(X_batch.shape)\n",
    "\n",
    "# S = np.array([[1,2,1], [6,6,6], [0,1,1]])\n",
    "# S_hot = (np.arange(S.max()+1) == S[...,None]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.array([[[1, 0, 4], [2, 4, 2], [3, 3, 0]], [[1, 4, 3], [1, 0, 0], [2, 2, 0]]])\n",
    "# utils.np_utils\n",
    "# type(keras.utils.np_utils)\n",
    "#from keras.utils.np_utils import to_categorical\n",
    "#incidence_y = to_categorical(y)\n",
    "incidence_y = np.zeros((*A.shape, 5))\n",
    "y_1 = A.ravel()\n",
    "# incidence_y[np.arange(A.shape[0]), np.arange(A.shape[1]), np.arange(A.shape[2]), A.ravel()] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the `sequence_length` argument to the static_rnn() or dynamic_rnn() functions to specify each sentence’s length (as discussed earlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent Neural Network (Static Unrolling Through Time)\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach still builds a graph containing one cell per time step. With such as large graph, you may even get out-of-memory (OOM) errors during backpropagation (especially with the limited memory of GPU cards), since it must store all tensor values during the forward pass so it can use them to compute gradients during the  reverse pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_neurons = 500\n",
    "\n",
    "# input tensors\n",
    "# X = [tf.placeholder(tf.float32, shape=[None, n_inputs], name='X'+str(1)) for i in range(n_steps)]\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "# swap the first two dimensions .. now in the form of (n_steps, n_examples, n_inputs) \n",
    "X_swap = tf.transpose(X, perm=[1, 0, 2])\n",
    "\n",
    "# X in a form of sequence\n",
    "X_seqs = tf.unstack(X_swap)\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "\n",
    "# 'output_seqs': is a Python list containing the output tensors for each time step. \n",
    "# 'states': is a tensor containing the final states of the network\n",
    "# When you are using basic cells, the final state is simply equal to the last output.\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, X_seqs, dtype=tf.float32)\n",
    "outputs = tf.transpose(tf.stack(output_seqs), perm=[1, 0, 2])\n",
    "\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batch})\n",
    "\n",
    "# print(outputs_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dynamic_rnn()  function uses a while_loop() operation to run over the cell the appropriate number of times, and you can set swap_memory=True if you want it to swap the GPU’s memory to the CPU’s memory during backpropagation to avoid OOM errors.\n",
    "\n",
    "Conveniently, it also accepts a single tensor for all inputs at every time step (shape [None, n_steps, n_inputs]) and it outputs a single tensor for all outputs at every time step (shape [None, n_steps, n_neurons]); there is no need to stack, unstack, or transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "n_neurons = 500\n",
    "seq_length = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32, sequence_length=seq_length)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val, states_val = sess.run(\n",
    "        [outputs, states], feed_dict={X: X_batch, seq_length: the_length_of_the_input_sequence_for_each_instance})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.01603885,  0.04096248,  0.07111038, ...,  0.0232278 ,\n",
       "          0.03350134,  0.00360562],\n",
       "        [ 0.05326501,  0.11043419,  0.04752845, ...,  0.09994518,\n",
       "         -0.03508453, -0.0374379 ],\n",
       "        [ 0.00754924,  0.00409045, -0.02264069, ...,  0.08742078,\n",
       "         -0.10536283, -0.02145722],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[-0.04733785, -0.01651455,  0.03473307, ..., -0.02926578,\n",
       "          0.01879792, -0.01249318],\n",
       "        [-0.02724044, -0.10794573,  0.06978463, ...,  0.03191889,\n",
       "          0.02742284, -0.10099661],\n",
       "        [ 0.0310605 , -0.09034449,  0.04587358, ..., -0.00392174,\n",
       "         -0.07773848, -0.07894513],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[-0.02914383, -0.05936295,  0.03612882, ...,  0.0502737 ,\n",
       "          0.04847324, -0.06416248],\n",
       "        [-0.04773682,  0.03193229,  0.08165961, ..., -0.03589242,\n",
       "          0.04765602,  0.02241219],\n",
       "        [-0.00562889,  0.06947322, -0.00607699, ...,  0.0755152 ,\n",
       "         -0.0585701 , -0.04800704],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       ..., \n",
       "       [[ 0.03243021,  0.03391967,  0.029643  , ...,  0.04078278,\n",
       "         -0.06133404, -0.06692258],\n",
       "        [-0.01361685,  0.06737334, -0.09843544, ..., -0.07982249,\n",
       "         -0.07153554, -0.01300579],\n",
       "        [ 0.08834534,  0.05951676,  0.03538301, ...,  0.10669087,\n",
       "         -0.01278857,  0.08429548],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[-0.02914383, -0.05936295,  0.03612882, ...,  0.0502737 ,\n",
       "          0.04847324, -0.06416248],\n",
       "        [-0.04773682,  0.03193229,  0.08165961, ..., -0.03589242,\n",
       "          0.04765602,  0.02241219],\n",
       "        [-0.05925288,  0.05501121, -0.00469486, ...,  0.09191324,\n",
       "         -0.03019751, -0.07621583],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.00185615, -0.01307382, -0.0386473 , ..., -0.03947619,\n",
       "         -0.05783295,  0.01933471],\n",
       "        [-0.10520703,  0.03078686, -0.03361303, ..., -0.09595061,\n",
       "         -0.10621709, -0.0496892 ],\n",
       "        [ 0.14001466,  0.02299338,  0.02925593, ...,  0.02961887,\n",
       "         -0.00068981, -0.02354765],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
