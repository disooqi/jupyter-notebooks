{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.contrib.keras.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-cceb18b08f91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.contrib.keras.utils'"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.keras as keras\n",
    "from tensorflow.contrib.keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold_1 = {'train':\"./seg_data/egy/data_1.train.conll\", \n",
    "          'dev':\"./seg_data/egy/data_1.dev.conll\", \n",
    "          'test':\"./seg_data/egy/data_1.test.conll\"}\n",
    "\n",
    "fold_2 = {'train':\"./seg_data/egy/data_2.train.conll\", \n",
    "          'dev':\"./seg_data/egy/data_2.dev.conll\", \n",
    "          'test':\"./seg_data/egy/data_2.test.conll\"}\n",
    "\n",
    "folds = {'1':fold_1, '2':fold_2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for training\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tweets (instances): 257\n",
      "number of steps (cells): 156\n",
      "number of units in the input layer (# features) 127\n",
      "\n",
      "The shape of the X_batch should be: (m, 156, 127), where `m` is the number of instances\n"
     ]
    }
   ],
   "source": [
    "train_sentences = list()\n",
    "train_trgs = list()\n",
    "\n",
    "index2trg = ['S', 'B', 'E', 'M', 'WB', 'EOT']\n",
    "trg2index = {'S': 0, 'B': 1, 'E': 2, 'M': 3, 'WB':4, 'EOT':5}\n",
    "\n",
    "ch_set = set()\n",
    "index2ch = ['<PAD>', '<UNK>']\n",
    "ch2index = dict() #{'<PAD>': 0, '<UNK>': 1}\n",
    "\n",
    "with codecs.open(folds['1']['train'], encoding=\"utf-8\") as eg_tr1:\n",
    "    sentence = list()\n",
    "    sentence_trg = list()\n",
    "    for i, line in enumerate(eg_tr1):\n",
    "        \n",
    "        line_elements = line.strip().split()\n",
    "        if line_elements:\n",
    "            ch_set.add(line_elements[0])\n",
    "            sentence.append(line_elements[0])\n",
    "            sentence_trg.append(line_elements[1])\n",
    "        else:\n",
    "            ch_set.add(\"EOT\")\n",
    "            sentence.append(\"EOT\")\n",
    "            sentence_trg.append(\"EOT\")\n",
    "            # print(sentence)\n",
    "            train_sentences.append(sentence)\n",
    "            train_trgs.append(sentence_trg)\n",
    "        \n",
    "            # print(train_sentences[0])\n",
    "            sentence = list()\n",
    "            sentence_trg = list()\n",
    "            \n",
    "            #             del sentence[:]\n",
    "            #             del sentence_trg[:]\n",
    "    else:\n",
    "        chars = list(ch_set)\n",
    "        index2ch.extend(chars)\n",
    "        for i, ch in enumerate(index2ch):\n",
    "            ch2index[ch] = i\n",
    "\n",
    "n_instances = len(train_sentences)\n",
    "n_steps = max(map(lambda x: len(x), train_sentences))\n",
    "n_inputs = len(index2ch)\n",
    "\n",
    "print('number of tweets (instances):',n_instances)\n",
    "print('number of steps (cells):', n_steps)\n",
    "print('number of units in the input layer (# features)', n_inputs)\n",
    "print()\n",
    "print('The shape of the X_batch should be: (m, {}, {}), where `m` is the number of instances'.format(n_steps, n_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare inputs for the network\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 156)\n",
      "(257, 156, 127)\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "#####  1  #######\n",
    "#################\n",
    "train_char_index = list()\n",
    "\n",
    "for sentence in train_sentences:\n",
    "    char_index = list(map(lambda ch: ch2index[ch], sentence))\n",
    "    train_char_index.append(char_index)\n",
    "\n",
    "# the_length of_the_input_sequence_for_each_instance\n",
    "the_length_of_the_input_sequence_for_each_instance = list(map(lambda x: len(x), train_sentences))\n",
    "\n",
    "\n",
    "###################################################\n",
    "#####  2 Padding for short sentences  #############\n",
    "###################################################\n",
    "# https://stackoverflow.com/questions/38592324/one-hot-encoding-using-numpy\n",
    "# https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t\n",
    "X = keras.preprocessing.sequence.pad_sequences(train_char_index, maxlen=n_steps, padding='post')\n",
    "print(X.shape)\n",
    "\n",
    "###########################################################\n",
    "#####  3 replace  char index with hot vector  #############\n",
    "###########################################################\n",
    "# https://stackoverflow.com/questions/36960320/convert-a-2d-matrix-to-a-3d-one-hot-matrix-numpy\n",
    "# http://localhost:8888/notebooks/ml/Neural%20Network%20-%20Backpropagation.ipynb\n",
    "targets = np.array(X).reshape(-1)\n",
    "X_one_hot = np.eye(n_inputs)[targets]\n",
    "X_batch = X_one_hot.reshape(n_instances,n_steps,n_inputs)\n",
    "# X_batch = tf.one_hot(X, n_inputs)\n",
    "print(X_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[[1, 0, 4], [2, 4, 2], [3, 3, 0]], [[1, 4, 3], [1, 0, 0], [2, 2, 0]]])\n",
    "# utils.np_utils\n",
    "# type(keras.utils.np_utils)\n",
    "#from keras.utils.np_utils import to_categorical\n",
    "#incidence_y = to_categorical(y)\n",
    "incidence_y = np.zeros((*A.shape, 5))\n",
    "y_1 = A.ravel()\n",
    "# incidence_y[np.arange(A.shape[0]), np.arange(A.shape[1]), np.arange(A.shape[2]), A.ravel()] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the `sequence_length` argument to the static_rnn() or dynamic_rnn() functions to specify each sentenceâ€™s length (as discussed earlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent Neural Network (Static Unrolling Through Time)\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_neurons = 500\n",
    "seq_length = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# input tensors\n",
    "# X = [tf.placeholder(tf.float32, shape=[None, n_inputs], name='X'+str(1)) for i in range(n_steps)]\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "# swap the first two dimensions .. now in the form of (n_steps, n_examples, n_inputs) \n",
    "X_swap = tf.transpose(X, perm=[1, 0, 2])\n",
    "\n",
    "# X in a form of sequence\n",
    "X_seqs = tf.unstack(X_swap)\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "\n",
    "# 'output_seqs': is a Python list containing the output tensors for each time step. \n",
    "# 'states': is a tensor containing the final states of the network\n",
    "# When you are using basic cells, the final state is simply equal to the last output.\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, X_seqs, dtype=tf.float32)\n",
    "outputs = tf.transpose(tf.stack(output_seqs), perm=[1, 0, 2])\n",
    "\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  7.78596709e-03  -3.94144356e-02   7.10680261e-02 ...,  -5.68997785e-02\n",
      "     7.04387277e-02   3.82299609e-02]\n",
      "  [  1.36554381e-02   1.77389930e-03  -5.75146228e-02 ...,  -2.00308971e-02\n",
      "     6.56124428e-02   1.23204440e-01]\n",
      "  [ -8.12847912e-02   5.10037430e-02   8.35492909e-02 ...,  -9.43109989e-02\n",
      "    -1.33422893e-02   6.35208338e-02]\n",
      "  ..., \n",
      "  [ -5.54687493e-02   1.82683155e-01  -6.51815347e-03 ...,   2.41238803e-01\n",
      "    -3.58380899e-02  -1.42197430e-01]\n",
      "  [ -7.01417327e-02   2.14439556e-01  -9.56205651e-03 ...,   2.39062324e-01\n",
      "    -3.91668454e-02  -1.06711201e-01]\n",
      "  [ -7.71463215e-02   1.68952256e-01  -1.81548283e-04 ...,   3.35559487e-01\n",
      "     5.55399880e-02  -8.08766410e-02]]\n",
      "\n",
      " [[  5.84787987e-02   1.02295643e-02   1.09754326e-02 ...,  -5.01259454e-02\n",
      "    -6.77819178e-02   9.52795986e-03]\n",
      "  [  2.88577881e-02   6.28785230e-03  -4.22063209e-02 ...,   2.84305755e-02\n",
      "     1.00755483e-01   5.29312119e-02]\n",
      "  [ -3.01660541e-02   1.33030400e-01  -2.07935404e-02 ...,   4.14608605e-02\n",
      "    -1.21798180e-02   5.67014143e-02]\n",
      "  ..., \n",
      "  [ -1.16487809e-01   1.21122941e-01  -6.77439943e-02 ...,   2.84831673e-01\n",
      "     1.37369350e-01  -1.75566703e-01]\n",
      "  [ -1.17335498e-01   1.18150555e-01  -6.66403174e-02 ...,   2.84094363e-01\n",
      "     1.35332242e-01  -1.73603311e-01]\n",
      "  [ -1.14998341e-01   1.18031174e-01  -6.46589175e-02 ...,   2.86332130e-01\n",
      "     1.37583300e-01  -1.74963772e-01]]\n",
      "\n",
      " [[ -1.18754734e-03   2.83929948e-02  -2.72575226e-02 ...,  -7.64833996e-03\n",
      "     2.22671088e-02   6.10945188e-02]\n",
      "  [ -5.26895039e-02   1.51860500e-02   9.67053026e-02 ...,  -2.43103970e-02\n",
      "     9.69716311e-02   2.46432684e-02]\n",
      "  [  4.37478982e-02  -8.46378952e-02  -5.73762506e-02 ...,   7.75803551e-02\n",
      "    -3.79559286e-02   3.97654213e-02]\n",
      "  ..., \n",
      "  [ -1.16492867e-01   1.20546937e-01  -6.36847839e-02 ...,   2.85572588e-01\n",
      "     1.33000165e-01  -1.75447807e-01]\n",
      "  [ -1.15544230e-01   1.17525101e-01  -6.60850033e-02 ...,   2.84786314e-01\n",
      "     1.31704107e-01  -1.72329336e-01]\n",
      "  [ -1.11527599e-01   1.18689969e-01  -6.46915063e-02 ...,   2.86386162e-01\n",
      "     1.35319129e-01  -1.73719272e-01]]\n",
      "\n",
      " ..., \n",
      " [[ -6.63335323e-02   4.77915406e-02   4.62854318e-02 ...,  -4.58795577e-02\n",
      "    -2.17877477e-02   5.98274171e-02]\n",
      "  [ -7.05522001e-02   1.00659914e-01  -2.79469043e-02 ...,   6.55177189e-03\n",
      "     3.39768603e-02  -3.74874361e-02]\n",
      "  [  1.03370482e-02   1.15932204e-01  -5.98539831e-03 ...,   3.81106115e-03\n",
      "     1.32045224e-01   8.74948427e-02]\n",
      "  ..., \n",
      "  [ -9.73909050e-02   1.46272451e-01  -5.71569651e-02 ...,   2.91409016e-01\n",
      "     1.12509884e-01  -1.70054182e-01]\n",
      "  [ -1.23886660e-01   1.35058910e-01  -6.64300844e-02 ...,   2.94075787e-01\n",
      "     1.04507908e-01  -1.60951272e-01]\n",
      "  [ -1.05112940e-01   1.31542698e-01  -6.16721623e-02 ...,   2.94800192e-01\n",
      "     1.15344130e-01  -1.64117619e-01]]\n",
      "\n",
      " [[ -1.18754734e-03   2.83929948e-02  -2.72575226e-02 ...,  -7.64833996e-03\n",
      "     2.22671088e-02   6.10945188e-02]\n",
      "  [ -5.26895039e-02   1.51860500e-02   9.67053026e-02 ...,  -2.43103970e-02\n",
      "     9.69716311e-02   2.46432684e-02]\n",
      "  [  3.38962898e-02  -9.26777944e-02   8.11384916e-02 ...,  -4.76214550e-02\n",
      "     1.04188494e-01   8.65995884e-02]\n",
      "  ..., \n",
      "  [ -1.15303189e-01   1.19557559e-01  -6.65196180e-02 ...,   2.84628838e-01\n",
      "     1.37229621e-01  -1.75610095e-01]\n",
      "  [ -1.15615085e-01   1.18442230e-01  -6.66752234e-02 ...,   2.84668952e-01\n",
      "     1.36299387e-01  -1.74987867e-01]\n",
      "  [ -1.15254737e-01   1.18467778e-01  -6.61170855e-02 ...,   2.85221905e-01\n",
      "     1.36518568e-01  -1.75333977e-01]]\n",
      "\n",
      " [[ -3.29642254e-03   3.72561514e-02  -2.31194813e-02 ...,   4.66142222e-02\n",
      "    -4.30315286e-02   2.28175074e-02]\n",
      "  [ -1.26726642e-01   4.20913361e-02  -1.87506189e-03 ...,   6.09577857e-02\n",
      "     2.21129525e-02   3.82087156e-02]\n",
      "  [  5.63483089e-02   1.10703364e-01  -4.63842154e-02 ...,  -1.90694164e-02\n",
      "    -1.11316862e-02   6.98183551e-02]\n",
      "  ..., \n",
      "  [ -9.20846760e-02   1.48590699e-01  -5.00753820e-02 ...,   2.96395242e-01\n",
      "     1.10612355e-01  -1.80066124e-01]\n",
      "  [ -1.06883667e-01   1.43476531e-01  -7.33857602e-02 ...,   2.84798384e-01\n",
      "     8.83204266e-02  -1.59415945e-01]\n",
      "  [ -7.13284090e-02   1.37705714e-01  -6.33993298e-02 ...,   2.83700377e-01\n",
      "     1.10089652e-01  -1.76421687e-01]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batch})\n",
    "\n",
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1],\n",
       "        [2],\n",
       "        [1]],\n",
       "\n",
       "       [[6],\n",
       "        [6],\n",
       "        [6]],\n",
       "\n",
       "       [[0],\n",
       "        [1],\n",
       "        [1]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = np.array([[1,2,1], [6,6,6], [0,1,1]])\n",
    "S_hot = (np.arange(S.max()+1) == S[...,None]).astype(int)\n",
    "\n",
    "S[...,None]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
